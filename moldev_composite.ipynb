{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f28f9c25",
   "metadata": {},
   "source": [
    "## Usage\n",
    "- Edit the settings in the cell below.\n",
    "- Cell -> Run All.\n",
    "- A Napari window will open, where you can scroll through your data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f02bd58b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# change this to point to your plate as seen in lmu_active1/instruments/Nano\n",
    "plate = 'lyu/140324-A53T P62 staining/140324-A53T P62 staining/2024-03-27/20378/TimePoint_1'\n",
    "plate = 'lyu/220824-hDA A53T-020924-1'\n",
    "plate = 'karkkael/microwell images/Plate1/2024-09-23/1/TimePoint_1/'\n",
    "\n",
    "# set lmu_active1 root folder for Linux or Windows\n",
    "#lmu_active1 = Path('/mnt/lmu_active1') # Linux\n",
    "#lmu_active1 = Path('L:\\lmu_active1') # Windows\n",
    "\n",
    "# define colors you want to use (as many as you have channels)\n",
    "#colormap = [\"yellow\", \"magenta\", \"cyan\"]\n",
    "colormap = [\"blue\", \"green\", \"red\"]\n",
    "colormap = [\"blue\", \"green\", \"red\", \"magenta\"]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bdbd4b64",
   "metadata": {},
   "source": [
    "## Code\n",
    "You don't need to make changes in the code cells below. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "014168b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from aicsimageio.aics_image import AICSImage\n",
    "from pathlib import Path\n",
    "import matplotlib.pyplot as plt\n",
    "import napari\n",
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd\n",
    "import platform\n",
    "\n",
    "def get_lmu_active1():\n",
    "    current_os = platform.system()\n",
    "    \n",
    "    if current_os == \"Windows\":\n",
    "        return \"L:\\\\lmu_active1\"\n",
    "    elif current_os == \"Linux\":\n",
    "        return \"/mnt/lmu_active1\"\n",
    "    else:\n",
    "        raise ValueError(f\"Unsupported operating system: {current_os}\")\n",
    "        \n",
    "# original image folder\n",
    "orig = get_lmu_active1() / Path('instruments/Nano') / Path(plate)\n",
    "#orig = Path('/home/user/nanodata') / Path(plate)\n",
    "orig = Path('/home/hajaalin/data/micro') / Path(plate)\n",
    "\n",
    "seg = Path('/home/user/nanodata/stardist') / Path(plate)\n",
    "seg = Path('/mnt/lmu_active1/airflow/nano') / plate.replace(' ', '_')\n",
    "#seg = Path('/tmp')\n",
    "seg = Path('/home/hajaalin/data/micro/karkkael/stardist_karkkael')\n",
    "print(seg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58e7f890",
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH = 'Path'\n",
    "DATE = 'Date'\n",
    "TIMEPOINT = 'TimePoint'\n",
    "ZSTEP = 'ZStep'\n",
    "PLATE = 'Plate'\n",
    "WELL = 'Well'\n",
    "SITE = 'Site'\n",
    "CHANNEL = 'Channel'\n",
    "UUID = 'UUID'\n",
    "\n",
    "def create_file_list(orig):\n",
    "    metadata_columns = {\n",
    "        'mc1': DATE,\n",
    "        'mc2': TIMEPOINT,\n",
    "        'mc3': ZSTEP,\n",
    "        'mc4': PLATE,\n",
    "        'mc5': WELL,\n",
    "        'mc6': SITE,\n",
    "        'mc7': CHANNEL,\n",
    "        'mc8': UUID,\n",
    "    }\n",
    "\n",
    "    files = [(str(x)) for x in orig.glob(\"**/*.tif\") if not \"thumb\" in x.name]\n",
    "    df = pd.DataFrame(files, columns=[PATH])\n",
    "\n",
    "    if not df.empty:\n",
    "        print(files[-1])\n",
    "\n",
    "    # Cross-platform pattern with dynamic column names\n",
    "    pattern = (\\\n",
    "        r'.*[/\\\\](?P<{mc1}>\\d{{4}}-\\d{{2}}-\\d{{2}})'\\\n",
    "        + r'[/\\\\][^/\\\\]*[/\\\\]TimePoint_(?P<{mc2}>\\d+)'\\\n",
    "        + r'(?:[/\\\\]ZStep_(?P<{mc3}>\\d+))?'\\\n",
    "        + r'[/\\\\](?P<{mc4}>[^_]+)_(?P<{mc5}>\\w\\d{{2}})_s(?P<{mc6}>\\d{{1,2}})_(?P<{mc7}>w\\d)'\\\n",
    "        + r'(?P<{mc8}>[A-F0-9]{{8}}-[A-F0-9]{{4}}-[A-F0-9]{{4}}-[A-F0-9]{{4}}-[A-F0-9]{{12}})'\\\n",
    "    ).format(**metadata_columns)\n",
    "    #pattern = r'.*[/\\\\](?P<{mc1}>\\d{{4}}-\\d{{2}}-\\d{{2}})[/\\\\][^/\\\\]*[/\\\\]TimePoint_(?P<{mc2}>\\d+)(?:[/\\\\]ZStep_(?P<{mc3}>\\d+))?[/\\\\](?P<{mc4}>[^_]+)_(?P<{mc5}>\\w\\d{{2}})_s(?P<{mc6}>\\d)_(?P<{mc7}>w\\d)'.format(**metadata_columns)\n",
    "    #pattern = r'.*[/\\\\](?P<{mc1}>\\d{{4}}-\\d{{2}}-\\d{{2}})[/\\\\][^/\\\\]*[/\\\\]TimePoint_(?P<{mc2}>\\d+)(?:[/\\\\]ZStep_(?P<{mc3}>\\d+))?[/\\\\](?P<{mc4}>[^_]+)_(?P<{mc5}>\\w\\d{{2}})_s(?P<{mc6}>\\d)_(?P<{mc7}>w\\d)(?P<{mc8}>[A-F0-9]{8}-[A-F0-9]{4}-[A-F0-9]{4}-[A-F0-9]{4}-[A-F0-9]{12})'.format(**metadata_columns)\n",
    "\n",
    "    print(pattern)\n",
    "    \n",
    "    # Apply the regex pattern and extract the desired columns\n",
    "    df_extracted = df[PATH].str.extract(pattern)\n",
    "    print()\n",
    "\n",
    "    # Add the extracted columns back to the original dataframe\n",
    "    df = df.join(df_extracted)\n",
    "\n",
    "    return df\n",
    "\n",
    "df = create_file_list(orig)\n",
    "df_seg = create_file_list(seg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57eadaf3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show the result\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07d5b75a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6419c53",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df_seg.shape)\n",
    "df_seg.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9ad0883",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df[df.Channel.isnull()].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df807522",
   "metadata": {},
   "outputs": [],
   "source": [
    "wavelengths = df.Channel.unique()\n",
    "print(wavelengths)\n",
    "\n",
    "wavelengths = sorted(wavelengths)\n",
    "print(wavelengths)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be1db189",
   "metadata": {},
   "outputs": [],
   "source": [
    "# separate Z-slices and projection images\n",
    "mask = df[ZSTEP].isnull()\n",
    "df2d = df[mask].copy().reset_index(drop=True)\n",
    "df3d = df[~mask].copy().reset_index(drop=True)\n",
    "df3d[ZSTEP] = df3d[ZSTEP].astype(int)\n",
    "\n",
    "df2d.sort_values(by=[PLATE, WELL, SITE, CHANNEL], inplace=True, ignore_index=True)\n",
    "df3d.sort_values(by=[PLATE, WELL, SITE, ZSTEP, CHANNEL], inplace=True, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8225cc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df2d.shape)\n",
    "df2d.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d98c2b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "df3d.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0176911e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# keep only segmentations that have corresponding projection images\n",
    "uuid_2d = df2d[[UUID]].copy()\n",
    "print(uuid_2d.shape)\n",
    "df_seg_2d = pd.merge(df_seg, uuid_2d, how='inner')\n",
    "print(df_seg_2d.shape)\n",
    "df_seg_2d.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93ad7399",
   "metadata": {},
   "outputs": [],
   "source": [
    "grouped2d = df2d.groupby(by=[PLATE, WELL, SITE]).agg(list)\n",
    "grouped2d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26a7b71d",
   "metadata": {},
   "outputs": [],
   "source": [
    "if not df3d.empty:\n",
    "    grouped3d = df3d.groupby(by=[PLATE, WELL, SITE]).agg(list)\n",
    "    grouped3d\n",
    "else:\n",
    "    print('No Z steps')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0411e527",
   "metadata": {},
   "outputs": [],
   "source": [
    "if not df_seg_2d.empty:\n",
    "    grouped_seg_2d = df_seg_2d.groupby(by=[PLATE, WELL, SITE]).agg(list)\n",
    "    grouped_seg_2d\n",
    "else:\n",
    "    print('No segmentations')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf09a221",
   "metadata": {},
   "outputs": [],
   "source": [
    "if not df3d.empty:\n",
    "    print(len(grouped3d.loc['Plate1', 'C07', '2'][PATH]))\n",
    "    print(len(grouped3d.loc['Plate1', 'C07', '2'][DATE]))\n",
    "    print(len(grouped3d.loc['Plate1', 'C07', '2'][TIMEPOINT]))\n",
    "    print(len(grouped3d.loc['Plate1', 'C07', '2'][ZSTEP]))\n",
    "    print(len(grouped3d.loc['Plate1', 'C07', '2'][CHANNEL]))\n",
    "    print(grouped3d.loc['Plate1', 'C07', '2'])\n",
    "    paths = grouped3d.loc['Plate1', 'C07', '2'][PATH]\n",
    "    for p in paths:\n",
    "        print(p)\n",
    "else:\n",
    "    print('No Z steps')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2a5c46b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import dask.array as da\n",
    "from aicsimageio import AICSImage\n",
    "\n",
    "def create_dask_array(grouped2d):\n",
    "    # Dictionary to store Dask arrays for each plate\n",
    "    plates = []\n",
    "    plate_stack = None\n",
    "\n",
    "    # Prebuild index mapping\n",
    "    index_map = {}\n",
    "\n",
    "    # Group by plate and well to handle multiple sites within a well\n",
    "    for plate, plate_group in grouped2d.groupby(PLATE):\n",
    "        wells = []\n",
    "\n",
    "        # Iterate over each well\n",
    "        for well, well_group in plate_group.groupby(WELL):\n",
    "            sites = []\n",
    "\n",
    "            # Iterate over each site\n",
    "            for site, site_group in well_group.groupby(SITE):\n",
    "                # At this point, we know the plate, well, and site\n",
    "                # Add an entry to index_mapping for this site\n",
    "                index_map[(plate, well, site)] = (len(plates), len(wells), len(sites))\n",
    "\n",
    "                print(site_group.columns)\n",
    "                print(site_group.shape)\n",
    "\n",
    "                # Explode list columns\n",
    "                exploded_site_group = site_group.explode([PATH, DATE, TIMEPOINT, CHANNEL, UUID])\n",
    "                print(exploded_site_group.shape)\n",
    "                print(exploded_site_group.apply(type).unique())\n",
    "                print(exploded_site_group.head())\n",
    "\n",
    "                channels = []\n",
    "\n",
    "                # Iterate over each channel and stack them for the current Z-step\n",
    "                for channel_path in exploded_site_group[PATH]:\n",
    "                    print(plate, well, site, channel_path)\n",
    "                    img = AICSImage(channel_path)\n",
    "                    # Use img.get_image_dask_data() for lazy loading of data\n",
    "                    dask_data = img.get_image_dask_data()\n",
    "                    #print(dask_data.shape)\n",
    "                    dask_data = dask_data.squeeze()\n",
    "                    #print(dask_data.shape)\n",
    "                    channels.append(dask_data)\n",
    "                print()\n",
    "                \n",
    "                # Stack channels for the current site\n",
    "                site_stack = da.stack(channels, axis=0)  # Stack Z-slices to form a 3D site-level array\n",
    "                print(site_stack.shape)\n",
    "                sites.append(site_stack)\n",
    "\n",
    "            # Stack all site-level arrays into a well-level array\n",
    "            well_stack = da.stack(sites, axis=0)  # Stack sites into a well\n",
    "            wells.append(well_stack)\n",
    "\n",
    "        # Stack all well-level arrays into a plate-level array\n",
    "        plate_stack = da.stack(wells, axis=0)  # Stack wells into a plate\n",
    "        plates.append(plate_stack)\n",
    "\n",
    "    final_dask_array = da.stack(plates)\n",
    "    return index_map, final_dask_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3f8885d",
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp = np.random.random((4, 100, 100))\n",
    "tmp.shape\n",
    "da.stack([tmp]).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3cc1da69",
   "metadata": {},
   "outputs": [],
   "source": [
    "index_map_2d, final_dask_array_2d = create_dask_array(grouped2d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04bcd585",
   "metadata": {},
   "outputs": [],
   "source": [
    "if not df_seg_2d.empty:\n",
    "    index_map_seg, final_dask_array_seg = create_dask_array(grouped_seg_2d)\n",
    "    print(final_dask_array_seg.shape)\n",
    "    #print(index_map_seg)\n",
    "    final_dask_array_seg[0, 0, 0, :, :, :]\n",
    "else:\n",
    "    print('No segmentations')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9815032",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(final_dask_array_2d.shape)\n",
    "if not df_seg_2d.empty:\n",
    "    print(final_dask_array_seg.shape)\n",
    "    #print(index_map_seg)\n",
    "    #final_dask_array_seg[0, 0, 0, :, :, :]\n",
    "#print(index_map_2d)\n",
    "print(da.squeeze(final_dask_array_seg, 3).shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4fc198d",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_dask_array_2d[0, 0, 0, :, :, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59b48c3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import dask.array as da\n",
    "from aicsimageio import AICSImage\n",
    "\n",
    "def create_dask_array_with_z(grouped3d):\n",
    "    # Dictionary to store Dask arrays for each plate\n",
    "    plates = []\n",
    "    plate_stack = None\n",
    "\n",
    "    # Prebuild index mapping\n",
    "    index_map = {}\n",
    "\n",
    "    # Group by plate and well to handle multiple sites within a well\n",
    "    for plate, plate_group in grouped3d.groupby(PLATE):\n",
    "        wells = []\n",
    "\n",
    "        # Iterate over each well\n",
    "        for well, well_group in plate_group.groupby(WELL):\n",
    "            sites = []\n",
    "\n",
    "            # Iterate over each site\n",
    "            for site, site_group in well_group.groupby(SITE):\n",
    "                z_steps = []\n",
    "\n",
    "                # At this point, we know the plate, well, and site\n",
    "                # Add an entry to index_mapping for this site\n",
    "                index_map[(plate, well, site)] = (len(plates), len(wells), len(sites))\n",
    "\n",
    "                print(site_group.columns)\n",
    "                print(site_group.shape)\n",
    "                print(site_group[ZSTEP].apply(type).unique())  # Check the type of elements in the ZStep column\n",
    "                #print(site_group[ZSTEP].head())  # Inspect the first few rows\n",
    "\n",
    "                # Explode both ZStep and Channel columns to ensure they correspond correctly\n",
    "                exploded_df = site_group.explode([PATH, DATE, TIMEPOINT, ZSTEP, CHANNEL])\n",
    "                print(exploded_df.shape)\n",
    "                print(exploded_df.apply(type).unique())\n",
    "                #print(exploded_df.head())\n",
    "\n",
    "                # Group by ZStep to handle stacking of channels for each Z-slice\n",
    "                for zstep, zstep_group in exploded_df.groupby(ZSTEP):\n",
    "                    channels = []\n",
    "\n",
    "                    # Iterate over each channel and stack them for the current Z-step\n",
    "                    for channel_path in zstep_group[PATH]:\n",
    "                        print(plate, well, site, zstep, channel_path)\n",
    "                        img = AICSImage(channel_path)\n",
    "                        # Use img.get_image_dask_data() for lazy loading of data\n",
    "                        dask_data = img.get_image_dask_data()\n",
    "                        #print(dask_data.shape)\n",
    "                        dask_data = dask_data.squeeze()\n",
    "                        #print(dask_data.shape)\n",
    "                        channels.append(dask_data)\n",
    "\n",
    "                    print()\n",
    "                    # Stack channels along a new axis (assume channels have same shape)\n",
    "                    z_step_stack = da.stack(channels, axis=0)  # Stack channels for this Z-step\n",
    "                    z_steps.append(z_step_stack)\n",
    "\n",
    "                print()\n",
    "                # Stack Z-steps into a full 3D array for the current site\n",
    "                site_stack = da.stack(z_steps, axis=0)  # Stack Z-slices to form a 3D site-level array\n",
    "                print(site_stack.shape)\n",
    "                sites.append(site_stack)\n",
    "\n",
    "            # Stack all site-level arrays into a well-level array\n",
    "            well_stack = da.stack(sites, axis=0)  # Stack sites into a well\n",
    "            wells.append(well_stack)\n",
    "\n",
    "        # Stack all well-level arrays into a plate-level array\n",
    "        plate_stack = da.stack(wells, axis=0)  # Stack wells into a plate\n",
    "        plates.append(plate_stack)\n",
    "\n",
    "    final_dask_array = da.stack(plates)\n",
    "    return index_map, final_dask_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c92a3e7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "if not df3d.empty:\n",
    "    index_map_3d, final_dask_array_3d = create_dask_array_with_z(grouped3d)\n",
    "    print(final_dask_array_3d.shape)\n",
    "    print(index_map_3d)\n",
    "    final_dask_array_3d[0, 0, 0, :, :, :, :]\n",
    "else:\n",
    "    print('No Z steps')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a798c360",
   "metadata": {},
   "outputs": [],
   "source": [
    "import napari\n",
    "import dask.array as da\n",
    "from magicgui import magicgui\n",
    "\n",
    "# Prebuild the index with (plate, well, site) -> dask slice\n",
    "#index_map = {}  # assuming this has been built during array construction\n",
    "plates = list(df2d[PLATE].unique())\n",
    "wells = list(df2d[WELL].unique())\n",
    "sites = list(df2d[SITE].unique())\n",
    "\n",
    "print(plates)\n",
    "print(wells)\n",
    "print(sites)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3673d772",
   "metadata": {},
   "outputs": [],
   "source": [
    "if not df3d.empty:\n",
    "    print(final_dask_array_3d.shape)\n",
    "    n_zsteps = final_dask_array_3d.shape[3]\n",
    "    print(n_zsteps)\n",
    "\n",
    "    # Expand 2D projection image to match the Z-axis length of the 3D image\n",
    "    expanded_2d_da = da.repeat(final_dask_array_2d[:, :, :, None, :, :, :], repeats=n_zsteps, axis=3)\n",
    "    print(expanded_2d_da.shape)\n",
    "\n",
    "    if not df_seg_2d.empty:\n",
    "        print(final_dask_array_seg.shape)\n",
    "        # Expand 2D segmentation image to match the Z-axis length of the 3D image\n",
    "        expanded_seg_da = da.repeat(final_dask_array_seg[:, :, :, None, :, :, :], repeats=n_zsteps, axis=3)\n",
    "        print(expanded_seg_da.shape)\n",
    "        # Squeeze out the channel dimension because for the real data it will be split in separate layers\n",
    "        expanded_seg_da = da.squeeze(expanded_seg_da, 4)\n",
    "        print(expanded_seg_da.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89fc7c7b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from qtpy.QtWidgets import QVBoxLayout, QWidget, QLabel, QComboBox\n",
    "\n",
    "# Initialize Napari viewer\n",
    "viewer = napari.Viewer()#order=[2,4,5,6])\n",
    "\n",
    "if not df3d.empty:\n",
    "    # Add 3D image with ZStep axis\n",
    "    viewer.add_image(\n",
    "        final_dask_array_3d, \n",
    "        channel_axis=4,  # Channel is 4th dimension in 3D\n",
    "        name=wavelengths,\n",
    "    )\n",
    "\n",
    "    # Add 2D projection image without ZStep axis\n",
    "    names_2d = [w + \" projection\" for w in wavelengths]\n",
    "    viewer.add_image(\n",
    "        expanded_2d_da, \n",
    "        channel_axis=4,  # Channel is 4th dimension in 3D\n",
    "        name=names_2d,\n",
    "    )\n",
    "    \n",
    "else:\n",
    "    # Add 2D projection image without ZStep axis\n",
    "    viewer.add_image(\n",
    "        final_dask_array_2d, \n",
    "        channel_axis=3,  # Channel is 3rd dimension in 2D\n",
    "        name=wavelengths,\n",
    "    )\n",
    "\n",
    "# Add labels\n",
    "if not df_seg_2d.empty:\n",
    "    viewer.add_labels(\n",
    "        expanded_seg_da,\n",
    "        #final_dask_array_seg, \n",
    "        #da.squeeze(final_dask_array_seg,3), \n",
    "        name='stardist_w1',\n",
    "    )\n",
    "\n",
    "# Set axis labels\n",
    "if not df3d.empty:\n",
    "    viewer.dims.axis_labels = ['Plate', 'Well', 'Site', 'Z-slice', 'X', 'Y']\n",
    "    # start from Z-slice 0 to have labels visible\n",
    "    viewer.dims.set_point(3,0)\n",
    "else:\n",
    "    viewer.dims.axis_labels = ['Plate', 'Well', 'Site', 'X', 'Y']\n",
    "    \n",
    "\n",
    "# start from well 0 to match pull-down\n",
    "viewer.dims.set_point(1,0)\n",
    "# start from site 0\n",
    "viewer.dims.set_point(2,0)\n",
    "\n",
    "\n",
    "\n",
    "# Create a widget for navigation\n",
    "IDX_WELL = 1\n",
    "class NavigationWidget(QWidget):\n",
    "    def __init__(self, wells):\n",
    "        super().__init__()\n",
    "        layout = QVBoxLayout()\n",
    "        \n",
    "        self.wells = wells\n",
    "\n",
    "        # Well selection\n",
    "        self.well_label = QLabel(\"Well\")\n",
    "        self.well_combo = QComboBox()\n",
    "        self.well_combo.addItems(wells)\n",
    "        self.well_combo.currentTextChanged.connect(self.update_image)\n",
    "\n",
    "        # Adding widgets to layout\n",
    "        layout.addWidget(self.well_label)\n",
    "        layout.addWidget(self.well_combo)\n",
    "\n",
    "        self.setLayout(layout)\n",
    "        \n",
    "        viewer.dims.events.point.connect(self._update_display)\n",
    "        \n",
    "    def _update_display(self):\n",
    "        #print(\"_update_display\")\n",
    "        slider_index = viewer.dims.point[IDX_WELL]\n",
    "        slider_index = round(slider_index)\n",
    "        self.well_combo.setCurrentText(self.wells[slider_index])\n",
    "\n",
    "    def update_image(self):\n",
    "        well = self.well_combo.currentText()\n",
    "        #print(well)  # Debugging print\n",
    "\n",
    "        # Select data based on plate, well, and site\n",
    "        if well in self.wells:\n",
    "            viewer.dims.set_point(IDX_WELL, self.wells.index(well))\n",
    "\n",
    "\n",
    "viewer.window.add_dock_widget(NavigationWidget(wells))\n",
    "napari.run()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d081eda9",
   "metadata": {},
   "outputs": [],
   "source": [
    "viewer.dims.point"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19496e1e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
