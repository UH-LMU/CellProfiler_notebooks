{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f28f9c25",
   "metadata": {},
   "source": [
    "## Usage\n",
    "- Edit the settings in the cell below.\n",
    "- Cell -> Run All.\n",
    "- A Napari window will open, where you can scroll through your data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f02bd58b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# change this to point to your plate as seen in lmu_active1/instruments/Nano\n",
    "plate = 'lyu/140324-A53T P62 staining/140324-A53T P62 staining/2024-03-27/20378/TimePoint_1'\n",
    "plate = 'karkkael/microwell images/Plate1/2024-09-23/1/TimePoint_1/'\n",
    "\n",
    "# set lmu_active1 root folder for Linux or Windows\n",
    "#lmu_active1 = Path('/mnt/lmu_active1') # Linux\n",
    "#lmu_active1 = Path('L:\\lmu_active1') # Windows\n",
    "\n",
    "# define colors you want to use (as many as you have channels)\n",
    "#colormap = [\"yellow\", \"magenta\", \"cyan\"]\n",
    "colormap = [\"blue\", \"green\", \"red\"]\n",
    "colormap = [\"blue\", \"green\", \"red\", \"magenta\"]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bdbd4b64",
   "metadata": {},
   "source": [
    "## Code\n",
    "You don't need to make changes in the code cells below. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "014168b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from aicsimageio.aics_image import AICSImage\n",
    "from pathlib import Path\n",
    "import matplotlib.pyplot as plt\n",
    "import napari\n",
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd\n",
    "import platform\n",
    "\n",
    "def get_lmu_active1():\n",
    "    current_os = platform.system()\n",
    "    \n",
    "    if current_os == \"Windows\":\n",
    "        return \"L:\\\\lmu_active1\"\n",
    "    elif current_os == \"Linux\":\n",
    "        return \"/mnt/lmu_active1\"\n",
    "    else:\n",
    "        raise ValueError(f\"Unsupported operating system: {current_os}\")\n",
    "        \n",
    "# original image folder\n",
    "orig = get_lmu_active1() / Path('instruments/Nano') / Path(plate)\n",
    "orig = Path('/home/user/nanodata') / Path(plate)\n",
    "orig = Path('/home/hajaalin/data/micro') / Path(plate)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57eadaf3",
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH = 'Path'\n",
    "DATE = 'Date'\n",
    "TIMEPOINT = 'TimePoint'\n",
    "ZSTEP = 'ZStep'\n",
    "PLATE = 'Plate'\n",
    "WELL = 'Well'\n",
    "SITE = 'Site'\n",
    "CHANNEL = 'Channel'\n",
    "\n",
    "files = [(str(x),x.parent,x.name) for x in orig.glob(\"**/*.tif\") if not \"thumb\" in x.name]\n",
    "df = pd.DataFrame(files, columns=[PATH,'DirName','FileName'])\n",
    "\n",
    "files = [(str(x)) for x in orig.glob(\"**/*.tif\") if not \"thumb\" in x.name]\n",
    "#files = ['/home/user/data/ael/microwell images/Plate1/2024-09-23/1/TimePoint_1/ZStep_9/Plate1_E05_s2_w1D10A7B39-96B7-4967-8EC6-22EA232A7725.tif']\n",
    "df = pd.DataFrame(files, columns=[PATH])\n",
    "\n",
    "print(files[-1])\n",
    "df.head()\n",
    "\n",
    "\n",
    "metadata_columns = {\n",
    "    'mc1': DATE,\n",
    "    'mc2': TIMEPOINT,\n",
    "    'mc3': ZSTEP,\n",
    "    'mc4': PLATE,\n",
    "    'mc5': WELL,\n",
    "    'mc6': SITE,\n",
    "    'mc7': CHANNEL\n",
    "}\n",
    "# Regular expression pattern\n",
    "pattern = r'.*/(?P<Date>\\d\\d\\d\\d-\\d\\d-\\d\\d)/[^/]*/TimePoint_(?P<TimePoint>\\d+)/(?:ZStep_(?P<ZStep>\\d+)/)?(?P<Plate>[^_]*)_(?P<Well>\\w\\d{2})_s(?P<Site>\\d)_(?P<Wavelength>w\\d)'\n",
    "\n",
    "# Cross-platform pattern with dynamic column names\n",
    "pattern = r'.*[/\\\\](?P<{mc1}>\\d{{4}}-\\d{{2}}-\\d{{2}})[/\\\\][^/\\\\]*[/\\\\]TimePoint_(?P<{mc2}>\\d+)(?:[/\\\\]ZStep_(?P<{mc3}>\\d+))?[/\\\\](?P<{mc4}>[^_]+)_(?P<{mc5}>\\w\\d{{2}})_s(?P<{mc6}>\\d)_(?P<{mc7}>w\\d)'.format(**metadata_columns)\n",
    "\n",
    "# Apply the regex pattern and extract the desired columns\n",
    "df_extracted = df[PATH].str.extract(pattern)\n",
    "print()\n",
    "\n",
    "# Add the extracted columns back to the original dataframe\n",
    "df = df.join(df_extracted)\n",
    "\n",
    "# Show the result\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07d5b75a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f395caee",
   "metadata": {},
   "outputs": [],
   "source": [
    "files[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df807522",
   "metadata": {},
   "outputs": [],
   "source": [
    "wavelengths = sorted(df.Channel.unique())\n",
    "wavelengths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3b44f12",
   "metadata": {},
   "outputs": [],
   "source": [
    "metadata_cols = metadata_columns.values()\n",
    "metadata_cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8225cc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "mask = df[ZSTEP].isnull()\n",
    "df2d = df[mask].copy().reset_index(drop=True)\n",
    "df3d = df[~mask].copy().reset_index(drop=True)\n",
    "df3d[ZSTEP] = df3d[ZSTEP].astype(int)\n",
    "\n",
    "df2d.sort_values(by=[PLATE, WELL, SITE, CHANNEL], inplace=True, ignore_index=True)\n",
    "df3d.sort_values(by=[PLATE, WELL, SITE, ZSTEP, CHANNEL], inplace=True, ignore_index=True)\n",
    "df3d.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93ad7399",
   "metadata": {},
   "outputs": [],
   "source": [
    "grouped2d = df2d.groupby(by=[PLATE, WELL, SITE]).agg(list)\n",
    "grouped2d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26a7b71d",
   "metadata": {},
   "outputs": [],
   "source": [
    "grouped3d = df3d.groupby(by=[PLATE, WELL, SITE]).agg(list)\n",
    "grouped3d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf09a221",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(grouped3d.loc['Plate1', 'C07', '2'][PATH]))\n",
    "print(len(grouped3d.loc['Plate1', 'C07', '2'][DATE]))\n",
    "print(len(grouped3d.loc['Plate1', 'C07', '2'][TIMEPOINT]))\n",
    "print(len(grouped3d.loc['Plate1', 'C07', '2'][ZSTEP]))\n",
    "print(len(grouped3d.loc['Plate1', 'C07', '2'][CHANNEL]))\n",
    "print(grouped3d.loc['Plate1', 'C07', '2'])\n",
    "paths = grouped3d.loc['Plate1', 'C07', '2'][PATH]\n",
    "for p in paths:\n",
    "    print(p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2a5c46b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import dask.array as da\n",
    "from aicsimageio import AICSImage\n",
    "\n",
    "def create_dask_array(grouped2d):\n",
    "    # Dictionary to store Dask arrays for each plate\n",
    "    plates = []\n",
    "    plate_stack = None\n",
    "\n",
    "    # Prebuild index mapping\n",
    "    index_map = {}\n",
    "\n",
    "    # Group by plate and well to handle multiple sites within a well\n",
    "    for plate, plate_group in grouped2d.groupby(PLATE):\n",
    "        wells = []\n",
    "\n",
    "        # Iterate over each well\n",
    "        for well, well_group in plate_group.groupby(WELL):\n",
    "            sites = []\n",
    "\n",
    "            # Iterate over each site\n",
    "            for site, site_group in well_group.groupby(SITE):\n",
    "                # At this point, we know the plate, well, and site\n",
    "                # Add an entry to index_mapping for this site\n",
    "                index_map[(plate, well, site)] = (len(plates), len(wells), len(sites))\n",
    "\n",
    "                print(site_group.columns)\n",
    "                print(site_group.shape)\n",
    "\n",
    "                # Explode list columns\n",
    "                exploded_site_group = site_group.explode([PATH, DATE, TIMEPOINT, CHANNEL])\n",
    "                print(exploded_site_group.shape)\n",
    "                print(exploded_site_group.apply(type).unique())\n",
    "                print(exploded_site_group.head())\n",
    "\n",
    "                channels = []\n",
    "\n",
    "                # Iterate over each channel and stack them for the current Z-step\n",
    "                for channel_path in exploded_site_group[PATH]:\n",
    "                    print(plate, well, site, channel_path)\n",
    "                    img = AICSImage(channel_path)\n",
    "                    # Use img.get_image_dask_data() for lazy loading of data\n",
    "                    dask_data = img.get_image_dask_data()\n",
    "                    #print(dask_data.shape)\n",
    "                    dask_data = dask_data.squeeze()\n",
    "                    #print(dask_data.shape)\n",
    "                    channels.append(dask_data)\n",
    "                print()\n",
    "                \n",
    "                # Stack channels for the current site\n",
    "                site_stack = da.stack(channels, axis=0)  # Stack Z-slices to form a 3D site-level array\n",
    "                print(site_stack.shape)\n",
    "                sites.append(site_stack)\n",
    "\n",
    "            # Stack all site-level arrays into a well-level array\n",
    "            well_stack = da.stack(sites, axis=0)  # Stack sites into a well\n",
    "            wells.append(well_stack)\n",
    "\n",
    "        # Stack all well-level arrays into a plate-level array\n",
    "        plate_stack = da.stack(wells, axis=0)  # Stack wells into a plate\n",
    "        plates.append(plate_stack)\n",
    "\n",
    "    final_dask_array = da.stack(plates)\n",
    "    return index_map, final_dask_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9815032",
   "metadata": {},
   "outputs": [],
   "source": [
    "index_map_2d, final_dask_array_2d = create_dask_array(grouped2d)\n",
    "print(final_dask_array_2d.shape)\n",
    "print(index_map_2d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59b48c3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import dask.array as da\n",
    "from aicsimageio import AICSImage\n",
    "\n",
    "def create_dask_array_with_z(grouped3d):\n",
    "    # Dictionary to store Dask arrays for each plate\n",
    "    plates = []\n",
    "    plate_stack = None\n",
    "\n",
    "    # Prebuild index mapping\n",
    "    index_map = {}\n",
    "\n",
    "    # Group by plate and well to handle multiple sites within a well\n",
    "    for plate, plate_group in grouped3d.groupby(PLATE):\n",
    "        wells = []\n",
    "\n",
    "        # Iterate over each well\n",
    "        for well, well_group in plate_group.groupby(WELL):\n",
    "            sites = []\n",
    "\n",
    "            # Iterate over each site\n",
    "            for site, site_group in well_group.groupby(SITE):\n",
    "                z_steps = []\n",
    "\n",
    "                # At this point, we know the plate, well, and site\n",
    "                # Add an entry to index_mapping for this site\n",
    "                index_map[(plate, well, site)] = (len(plates), len(wells), len(sites))\n",
    "\n",
    "                print(site_group.columns)\n",
    "                print(site_group.shape)\n",
    "                print(site_group[ZSTEP].apply(type).unique())  # Check the type of elements in the ZStep column\n",
    "                #print(site_group[ZSTEP].head())  # Inspect the first few rows\n",
    "\n",
    "                # Explode both ZStep and Channel columns to ensure they correspond correctly\n",
    "                exploded_df = site_group.explode([PATH, DATE, TIMEPOINT, ZSTEP, CHANNEL])\n",
    "                print(exploded_df.shape)\n",
    "                print(exploded_df.apply(type).unique())\n",
    "                #print(exploded_df.head())\n",
    "\n",
    "                # Group by ZStep to handle stacking of channels for each Z-slice\n",
    "                for zstep, zstep_group in exploded_df.groupby(ZSTEP):\n",
    "                    channels = []\n",
    "\n",
    "                    # Iterate over each channel and stack them for the current Z-step\n",
    "                    for channel_path in zstep_group[PATH]:\n",
    "                        print(plate, well, site, zstep, channel_path)\n",
    "                        img = AICSImage(channel_path)\n",
    "                        # Use img.get_image_dask_data() for lazy loading of data\n",
    "                        dask_data = img.get_image_dask_data()\n",
    "                        #print(dask_data.shape)\n",
    "                        dask_data = dask_data.squeeze()\n",
    "                        #print(dask_data.shape)\n",
    "                        channels.append(dask_data)\n",
    "\n",
    "                    print()\n",
    "                    # Stack channels along a new axis (assume channels have same shape)\n",
    "                    z_step_stack = da.stack(channels, axis=0)  # Stack channels for this Z-step\n",
    "                    z_steps.append(z_step_stack)\n",
    "\n",
    "                print()\n",
    "                # Stack Z-steps into a full 3D array for the current site\n",
    "                site_stack = da.stack(z_steps, axis=0)  # Stack Z-slices to form a 3D site-level array\n",
    "                print(site_stack.shape)\n",
    "                sites.append(site_stack)\n",
    "\n",
    "            # Stack all site-level arrays into a well-level array\n",
    "            well_stack = da.stack(sites, axis=0)  # Stack sites into a well\n",
    "            wells.append(well_stack)\n",
    "\n",
    "        # Stack all well-level arrays into a plate-level array\n",
    "        plate_stack = da.stack(wells, axis=0)  # Stack wells into a plate\n",
    "        plates.append(plate_stack)\n",
    "\n",
    "    final_dask_array = da.stack(plates)\n",
    "    return index_map, final_dask_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c92a3e7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "index_map_3d, final_dask_array_3d = create_dask_array_with_z(grouped3d)\n",
    "print(final_dask_array_3d.shape)\n",
    "print(index_map_3d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2842ec36",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_dask_array[0, 0, 0, :, :, :, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a798c360",
   "metadata": {},
   "outputs": [],
   "source": [
    "import napari\n",
    "import dask.array as da\n",
    "from magicgui import magicgui\n",
    "\n",
    "# Prebuild the index with (plate, well, site) -> dask slice\n",
    "#index_map = {}  # assuming this has been built during array construction\n",
    "plates = list(df3d[PLATE].unique())\n",
    "wells = list(df3d[WELL].unique())\n",
    "sites = list(df3d[SITE].unique())\n",
    "\n",
    "print(plates)\n",
    "print(wells)\n",
    "print(sites)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad41cb32",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize Napari viewer\n",
    "viewer = napari.Viewer()\n",
    "   \n",
    "# Function to update the image and retain contrast settings\n",
    "def update_image(data_slice):\n",
    "    # Get current contrast limits if the image layer exists\n",
    "    contrast_limits = None\n",
    "    if viewer.layers:\n",
    "        contrast_limits = [l.contrast_limits for l in viewer.layers]\n",
    "      \n",
    "    # Remove the previous image layer\n",
    "    viewer.layers.clear()\n",
    "\n",
    "    # Re-add the image layer with the new data and channel axis\n",
    "    new_layer = viewer.add_image(final_dask_array[data_slice],\n",
    "                                 channel_axis=1,  # Keep channel axis\n",
    "                                 contrast_limits=contrast_limits,\n",
    "                                 name=wavelengths)\n",
    "\n",
    "update_image(index_map[plates[0],wells[0],sites[0]])\n",
    "\n",
    "# Create pull-down for plates and wells\n",
    "@magicgui(plate={\"choices\": plates}, well={\"choices\": wells}, site={\"choices\": sites, \"label\": \"Site\"}, call_button=False, auto_call=True)\n",
    "def navigation_widget(plate: str, well: str, site: str):  # Change site type to str\n",
    "    print(plate, well, site)  # Debug print\n",
    "    # Select data based on plate, well, and site\n",
    "    if (plate, well, site) in index_map:\n",
    "        data_slice = index_map[(plate, well, site)]\n",
    "        print(\"data_slice: \" + str(data_slice))\n",
    "        print(final_dask_array[data_slice].shape)\n",
    "        \n",
    "        update_image(data_slice)\n",
    "    else:\n",
    "        print(f\"No data found for (plate: {plate}, well: {well}, site: {site})\")  # Print message if no data\n",
    "\n",
    "# Add widget to Napari viewer\n",
    "viewer.window.add_dock_widget(navigation_widget)\n",
    "napari.run()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89fc7c7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(type(image_layer))\n",
    "print(type(image_layer[0]))\n",
    "print(image_layer[0].contrast_limits)\n",
    "print(image_layer[0].name)\n",
    "contrast_limits = [l.contrast_limits for l in image_layer]\n",
    "print(contrast_limits)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
