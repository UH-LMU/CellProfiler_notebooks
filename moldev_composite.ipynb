{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f28f9c25",
   "metadata": {},
   "source": [
    "## Usage\n",
    "- Edit the settings in the cell below.\n",
    "- Cell -> Run All.\n",
    "- A Napari window will open, where you can scroll through your data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f02bd58b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# change this to point to your plate as seen in lmu_active1/instruments/Nano\n",
    "plate = 'lyu/140324-A53T P62 staining/140324-A53T P62 staining/2024-03-27/20378/TimePoint_1'\n",
    "plate = 'karkkael/microwell images/Plate1/2024-09-23/1/TimePoint_1/'\n",
    "\n",
    "# set lmu_active1 root folder for Linux or Windows\n",
    "#lmu_active1 = Path('/mnt/lmu_active1') # Linux\n",
    "#lmu_active1 = Path('L:\\lmu_active1') # Windows\n",
    "\n",
    "# define colors you want to use (as many as you have channels)\n",
    "#colormap = [\"yellow\", \"magenta\", \"cyan\"]\n",
    "colormap = [\"blue\", \"green\", \"red\"]\n",
    "colormap = [\"blue\", \"green\", \"red\", \"magenta\"]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bdbd4b64",
   "metadata": {},
   "source": [
    "## Code\n",
    "You don't need to make changes in the code cells below. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "014168b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from aicsimageio.aics_image import AICSImage\n",
    "from pathlib import Path\n",
    "import matplotlib.pyplot as plt\n",
    "import napari\n",
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd\n",
    "import platform\n",
    "\n",
    "def get_lmu_active1():\n",
    "    current_os = platform.system()\n",
    "    \n",
    "    if current_os == \"Windows\":\n",
    "        return \"L:\\\\lmu_active1\"\n",
    "    elif current_os == \"Linux\":\n",
    "        return \"/mnt/lmu_active1\"\n",
    "    else:\n",
    "        raise ValueError(f\"Unsupported operating system: {current_os}\")\n",
    "        \n",
    "# original image folder\n",
    "orig = get_lmu_active1() / Path('instruments/Nano') / Path(plate)\n",
    "orig = Path('/home/user/nanodata') / Path(plate)\n",
    "#orig = Path('/home/hajaalin/data/micro') / Path(plate)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57eadaf3",
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH = 'Path'\n",
    "DATE = 'Date'\n",
    "TIMEPOINT = 'TimePoint'\n",
    "ZSTEP = 'ZStep'\n",
    "PLATE = 'Plate'\n",
    "WELL = 'Well'\n",
    "SITE = 'Site'\n",
    "CHANNEL = 'Channel'\n",
    "\n",
    "files = [(str(x),x.parent,x.name) for x in orig.glob(\"**/*.tif\") if not \"thumb\" in x.name]\n",
    "df = pd.DataFrame(files, columns=[PATH,'DirName','FileName'])\n",
    "\n",
    "files = [(str(x)) for x in orig.glob(\"**/*.tif\") if not \"thumb\" in x.name]\n",
    "#files = ['/home/user/data/ael/microwell images/Plate1/2024-09-23/1/TimePoint_1/ZStep_9/Plate1_E05_s2_w1D10A7B39-96B7-4967-8EC6-22EA232A7725.tif']\n",
    "df = pd.DataFrame(files, columns=[PATH])\n",
    "\n",
    "print(files[-1])\n",
    "df.head()\n",
    "\n",
    "\n",
    "metadata_columns = {\n",
    "    'mc1': DATE,\n",
    "    'mc2': TIMEPOINT,\n",
    "    'mc3': ZSTEP,\n",
    "    'mc4': PLATE,\n",
    "    'mc5': WELL,\n",
    "    'mc6': SITE,\n",
    "    'mc7': CHANNEL\n",
    "}\n",
    "# Regular expression pattern\n",
    "pattern = r'.*/(?P<Date>\\d\\d\\d\\d-\\d\\d-\\d\\d)/[^/]*/TimePoint_(?P<TimePoint>\\d+)/(?:ZStep_(?P<ZStep>\\d+)/)?(?P<Plate>[^_]*)_(?P<Well>\\w\\d{2})_s(?P<Site>\\d)_(?P<Wavelength>w\\d)'\n",
    "\n",
    "# Cross-platform pattern with dynamic column names\n",
    "pattern = r'.*[/\\\\](?P<{mc1}>\\d{{4}}-\\d{{2}}-\\d{{2}})[/\\\\][^/\\\\]*[/\\\\]TimePoint_(?P<{mc2}>\\d+)(?:[/\\\\]ZStep_(?P<{mc3}>\\d+))?[/\\\\](?P<{mc4}>[^_]+)_(?P<{mc5}>\\w\\d{{2}})_s(?P<{mc6}>\\d)_(?P<{mc7}>w\\d)'.format(**metadata_columns)\n",
    "\n",
    "# Apply the regex pattern and extract the desired columns\n",
    "df_extracted = df[PATH].str.extract(pattern)\n",
    "print()\n",
    "\n",
    "# Add the extracted columns back to the original dataframe\n",
    "df = df.join(df_extracted)\n",
    "\n",
    "# Show the result\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07d5b75a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f395caee",
   "metadata": {},
   "outputs": [],
   "source": [
    "files[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df807522",
   "metadata": {},
   "outputs": [],
   "source": [
    "wavelengths = sorted(df.Channel.unique())\n",
    "wavelengths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3b44f12",
   "metadata": {},
   "outputs": [],
   "source": [
    "metadata_cols = metadata_columns.values()\n",
    "metadata_cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8225cc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "mask = df[ZSTEP].isnull()\n",
    "df2d = df[mask].copy().reset_index(drop=True)\n",
    "df3d = df[~mask].copy().reset_index(drop=True)\n",
    "df3d[ZSTEP] = df3d[ZSTEP].astype(int)\n",
    "\n",
    "df2d.sort_values(by=[PLATE, WELL, SITE, CHANNEL], inplace=True, ignore_index=True)\n",
    "df3d.sort_values(by=[PLATE, WELL, SITE, ZSTEP, CHANNEL], inplace=True, ignore_index=True)\n",
    "df3d.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93ad7399",
   "metadata": {},
   "outputs": [],
   "source": [
    "grouped2d = df2d.groupby(by=[PLATE, WELL, SITE]).agg(list)\n",
    "grouped2d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26a7b71d",
   "metadata": {},
   "outputs": [],
   "source": [
    "grouped3d = df3d.groupby(by=[PLATE, WELL, SITE]).agg(list)\n",
    "grouped3d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf09a221",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(grouped3d.loc['Plate1', 'C07', '2'][PATH]))\n",
    "print(len(grouped3d.loc['Plate1', 'C07', '2'][DATE]))\n",
    "print(len(grouped3d.loc['Plate1', 'C07', '2'][TIMEPOINT]))\n",
    "print(len(grouped3d.loc['Plate1', 'C07', '2'][ZSTEP]))\n",
    "print(len(grouped3d.loc['Plate1', 'C07', '2'][CHANNEL]))\n",
    "print(grouped3d.loc['Plate1', 'C07', '2'])\n",
    "paths = grouped3d.loc['Plate1', 'C07', '2'][PATH]\n",
    "for p in paths:\n",
    "    print(p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2a5c46b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import dask.array as da\n",
    "from aicsimageio import AICSImage\n",
    "\n",
    "# Dictionary to store Dask arrays for each plate\n",
    "plates = []\n",
    "plate_stack = None\n",
    "\n",
    "# Prebuild index mapping\n",
    "index_map = {}\n",
    "\n",
    "# Group by plate and well to handle multiple sites within a well\n",
    "for plate, plate_group in grouped3d.groupby(PLATE):\n",
    "    wells = []\n",
    "    \n",
    "    # Iterate over each well\n",
    "    for well, well_group in plate_group.groupby(WELL):\n",
    "        sites = []\n",
    "        \n",
    "        # Iterate over each site\n",
    "        for site, site_group in well_group.groupby(SITE):\n",
    "            z_steps = []\n",
    "            \n",
    "            # At this point, we know the plate, well, and site\n",
    "            # Add an entry to index_mapping for this site\n",
    "            index_map[(plate, well, site)] = (len(plates), len(wells), len(sites))\n",
    "\n",
    "            print(site_group.columns)\n",
    "            print(site_group.shape)\n",
    "            print(site_group[ZSTEP].apply(type).unique())  # Check the type of elements in the ZStep column\n",
    "            #print(site_group[ZSTEP].head())  # Inspect the first few rows\n",
    "            \n",
    "            # Explode both ZStep and Channel columns to ensure they correspond correctly\n",
    "            exploded_df = site_group.explode([PATH, DATE, TIMEPOINT, ZSTEP, CHANNEL])\n",
    "            print(exploded_df.shape)\n",
    "            print(exploded_df.apply(type).unique())\n",
    "            #print(exploded_df.head())\n",
    "\n",
    "            # Group by ZStep to handle stacking of channels for each Z-slice\n",
    "            for zstep, zstep_group in exploded_df.groupby(ZSTEP):\n",
    "                channels = []\n",
    "                \n",
    "                # Iterate over each channel and stack them for the current Z-step\n",
    "                for channel_path in zstep_group[PATH]:\n",
    "                    print(plate, well, site, zstep, channel_path)\n",
    "                    img = AICSImage(channel_path)\n",
    "                    # Use img.get_image_dask_data() for lazy loading of data\n",
    "                    dask_data = img.get_image_dask_data()\n",
    "                    #print(dask_data.shape)\n",
    "                    dask_data = dask_data.squeeze()\n",
    "                    #print(dask_data.shape)\n",
    "                    channels.append(dask_data)\n",
    "    \n",
    "                print()\n",
    "                # Stack channels along a new axis (assume channels have same shape)\n",
    "                z_step_stack = da.stack(channels, axis=0)  # Stack channels for this Z-step\n",
    "                z_steps.append(z_step_stack)\n",
    "            \n",
    "            print()\n",
    "            # Stack Z-steps into a full 3D array for the current site\n",
    "            site_stack = da.stack(z_steps, axis=0)  # Stack Z-slices to form a 3D site-level array\n",
    "            print(site_stack.shape)\n",
    "            sites.append(site_stack)\n",
    "        \n",
    "        # Stack all site-level arrays into a well-level array\n",
    "        well_stack = da.stack(sites, axis=0)  # Stack sites into a well\n",
    "        wells.append(well_stack)\n",
    "    \n",
    "    # Stack all well-level arrays into a plate-level array\n",
    "    plate_stack = da.stack(wells, axis=0)  # Stack wells into a plate\n",
    "    plates.append(plate_stack)\n",
    "        \n",
    "final_dask_array = da.stack(plates)\n",
    "print(final_dask_array.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9815032",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(final_dask_array.shape)\n",
    "print(index_map)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2842ec36",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_dask_array[0, 0, 0, :, :, :, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a798c360",
   "metadata": {},
   "outputs": [],
   "source": [
    "import napari\n",
    "import dask.array as da\n",
    "from magicgui import magicgui\n",
    "\n",
    "# Prebuild the index with (plate, well, site) -> dask slice\n",
    "#index_map = {}  # assuming this has been built during array construction\n",
    "plates = list(df3d[PLATE].unique())\n",
    "wells = list(df3d[WELL].unique())\n",
    "sites = list(df3d[SITE].unique())\n",
    "\n",
    "print(plates)\n",
    "print(wells)\n",
    "print(sites)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad41cb32",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize Napari viewer\n",
    "viewer = napari.Viewer()\n",
    "\n",
    "# Add Dask array to the viewer with initial data\n",
    "image_layer = viewer.add_image(final_dask_array[0, 0, 0, :, :, :, :], channel_axis=1)  # Keep channel_axis=1\n",
    "\n",
    "# Create pull-down for plates and wells\n",
    "@magicgui(plate={\"choices\": plates}, well={\"choices\": wells}, site={\"choices\": sites, \"label\": \"Site\"})\n",
    "def navigation_widget(plate: str, well: str, site: str):  # Change site type to str\n",
    "    print(plate, well, site)  # Debug print\n",
    "    # Select data based on plate, well, and site\n",
    "    if (plate, well, site) in index_map:\n",
    "        data_slice = index_map[(plate, well, site)]\n",
    "        image_layer[0].data = final_dask_array[data_slice]  # Update the image layer\n",
    "    else:\n",
    "        print(f\"No data found for (plate: {plate}, well: {well}, site: {site})\")  # Print message if no data\n",
    "\n",
    "# Add widget to Napari viewer\n",
    "viewer.window.add_dock_widget(navigation_widget)\n",
    "napari.run()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4fe8966",
   "metadata": {},
   "outputs": [],
   "source": [
    "import napari\n",
    "from qtpy.QtWidgets import QVBoxLayout, QWidget, QLabel, QComboBox\n",
    "\n",
    "# Initialize Napari viewer\n",
    "viewer = napari.Viewer()\n",
    "\n",
    "# Add Dask array to the viewer with initial data\n",
    "image_layer = viewer.add_image(final_dask_array[0, 0, 0, :, :, :, :], channel_axis=1)#[0]\n",
    "\n",
    "# Create a widget for navigation\n",
    "class NavigationWidget(QWidget):\n",
    "    def __init__(self, plates, wells, sites):\n",
    "        super().__init__()\n",
    "        layout = QVBoxLayout()\n",
    "\n",
    "        # Plate selection\n",
    "        self.plate_label = QLabel(\"Plate\")\n",
    "        self.plate_combo = QComboBox()\n",
    "        self.plate_combo.addItems(plates)\n",
    "        self.plate_combo.currentTextChanged.connect(self.update_image)\n",
    "\n",
    "        # Well selection\n",
    "        self.well_label = QLabel(\"Well\")\n",
    "        self.well_combo = QComboBox()\n",
    "        self.well_combo.addItems(wells)\n",
    "        self.well_combo.currentTextChanged.connect(self.update_image)\n",
    "\n",
    "        # Site selection\n",
    "        self.site_label = QLabel(\"Site\")\n",
    "        self.site_combo = QComboBox()\n",
    "        self.site_combo.addItems(sites)\n",
    "        self.site_combo.currentTextChanged.connect(self.update_image)\n",
    "\n",
    "        # Adding widgets to layout\n",
    "        layout.addWidget(self.plate_label)\n",
    "        layout.addWidget(self.plate_combo)\n",
    "        layout.addWidget(self.well_label)\n",
    "        layout.addWidget(self.well_combo)\n",
    "        layout.addWidget(self.site_label)\n",
    "        layout.addWidget(self.site_combo)\n",
    "\n",
    "        self.setLayout(layout)\n",
    "\n",
    "    def update_image(self):\n",
    "        plate = self.plate_combo.currentText()\n",
    "        well = self.well_combo.currentText()\n",
    "        site = self.site_combo.currentText()\n",
    "        print(plate, well, site)  # Debugging print\n",
    "\n",
    "        # Select data based on plate, well, and site\n",
    "        if (plate, well, site) in index_map:\n",
    "            data_slice = index_map[(plate, well, site)]\n",
    "            print(f\"Updating image with data slice: {data_slice}\")  # Debugging print\n",
    "            \n",
    "            # Update the image layer data correctly\n",
    "            image_layer[0].data = final_dask_array[data_slice].compute()  # Ensure we compute the Dask array to numpy\n",
    "\n",
    "# Add the navigation widget to the viewer\n",
    "navigation_widget = NavigationWidget(plates, wells, sites)\n",
    "viewer.window.add_dock_widget(navigation_widget)\n",
    "\n",
    "napari.run()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f18c42e",
   "metadata": {},
   "outputs": [],
   "source": [
    "napari.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c390f05",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dummy final_dask_array from earlier\n",
    "#final_dask_array = da.random.random((1, 6, 1, 3, 4, 1843, 1843))\n",
    "\n",
    "# Initialize Napari viewer\n",
    "viewer = napari.Viewer()\n",
    "\n",
    "# Add Dask array to the viewer with initial data. Note that channel axis is relative to the sliced part\n",
    "image_layer = viewer.add_image(final_dask_array[0, 0, 0, :, :, :, :], channel_axis=1)\n",
    "\n",
    "# Create pull-down for plates and wells\n",
    "@magicgui(plate={\"choices\": plates}, well={\"choices\": wells}, site={\"max\": len(sites)-1, \"label\": \"Site\"}, call_button=False)\n",
    "def navigation_widget(plate: str, well: str, site: int):\n",
    "    print(plate, well, site)\n",
    "    # Select data based on plate, well, and site\n",
    "    if (plate, well, site) in index_map:\n",
    "        data_slice = index_map[(plate, well, site)]\n",
    "        image_layer.data = final_dask_array[data_slice]\n",
    "\n",
    "# Add widget to Napari viewer\n",
    "viewer.window.add_dock_widget(navigation_widget)\n",
    "napari.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75d0c805",
   "metadata": {},
   "outputs": [],
   "source": [
    "from napari.utils import notifications\n",
    "from qtpy.QtWidgets import QComboBox, QSlider, QLabel, QVBoxLayout, QWidget\n",
    "\n",
    "# Napari viewer setup\n",
    "viewer = napari.Viewer()\n",
    "\n",
    "# Creating widgets\n",
    "class CustomWidget(QWidget):\n",
    "    def __init__(self, viewer):\n",
    "        super().__init__()\n",
    "        self.viewer = viewer\n",
    "        \n",
    "        # Plate dropdown\n",
    "        self.plate_label = QLabel(\"Select Plate:\")\n",
    "        self.plate_dropdown = QComboBox()\n",
    "        self.plate_dropdown.addItems(df['Plate'].unique())  # Populate with unique plates\n",
    "        \n",
    "        # Well dropdown\n",
    "        self.well_label = QLabel(\"Select Well:\")\n",
    "        self.well_dropdown = QComboBox()\n",
    "        \n",
    "        # Site slider\n",
    "        self.site_label = QLabel(\"Select Site:\")\n",
    "        self.site_slider = QSlider()\n",
    "        self.site_slider.setMinimum(0)\n",
    "        self.site_slider.setMaximum(df['Site'].nunique() - 1)\n",
    "        \n",
    "        # Layout\n",
    "        layout = QVBoxLayout()\n",
    "        layout.addWidget(self.plate_label)\n",
    "        layout.addWidget(self.plate_dropdown)\n",
    "        layout.addWidget(self.well_label)\n",
    "        layout.addWidget(self.well_dropdown)\n",
    "        layout.addWidget(self.site_label)\n",
    "        layout.addWidget(self.site_slider)\n",
    "        self.setLayout(layout)\n",
    "        \n",
    "        # Connect signals\n",
    "        self.plate_dropdown.currentTextChanged.connect(self.update_wells)\n",
    "        self.well_dropdown.currentTextChanged.connect(self.update_viewer)\n",
    "        self.site_slider.valueChanged.connect(self.update_viewer)\n",
    "\n",
    "    def update_wells(self):\n",
    "        plate = self.plate_dropdown.currentText()\n",
    "        wells = df[df['Plate'] == plate]['Well'].unique()\n",
    "        self.well_dropdown.clear()\n",
    "        self.well_dropdown.addItems(wells)\n",
    "        \n",
    "    def update_viewer(self):\n",
    "        plate = self.plate_dropdown.currentText()\n",
    "        well = self.well_dropdown.currentText()\n",
    "        site = self.site_slider.value()\n",
    "\n",
    "        # Fetch the corresponding data\n",
    "        key = (plate, well, site)\n",
    "        if key in index_mapping:\n",
    "            # Display the Dask array slice corresponding to the selected plate, well, and site\n",
    "            zsteps = index_mapping[key]['zstep']\n",
    "            channels = index_mapping[key]['channels']\n",
    "            notifications.show_info(f\"Plate: {plate}, Well: {well}, Site: {site}, ZSteps: {zsteps}, Channels: {channels}\")\n",
    "            # Update viewer with the new image data for the selected well, site, etc.\n",
    "            # Assuming the data is already loaded into dask_array, show the corresponding slice\n",
    "            self.viewer.layers.clear()\n",
    "            self.viewer.add_image(dask_array[plate_index, well_index, site_index])\n",
    "\n",
    "widget = CustomWidget(viewer)\n",
    "viewer.window.add_dock_widget(widget, area='right')\n",
    "\n",
    "napari.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64a3879c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import napari\n",
    "from magicgui import magicgui\n",
    "import dask.array as da\n",
    "\n",
    "# Assuming `data` is your 6x1x3x4x1843x1843 Dask array\n",
    "data_shape = (6, 1, 3, 4, 1843, 1843)  # Update this to the actual Dask array\n",
    "dask_array = da.random.random(data_shape)  # Replace with actual dask array\n",
    "dask_array = plate_stack\n",
    "\n",
    "# Create Napari viewer\n",
    "viewer = napari.Viewer()\n",
    "\n",
    "# Add the dask array as an image layer, with the channels as separate dimensions\n",
    "image_layer = viewer.add_image(\n",
    "    dask_array, \n",
    "    channel_axis=3,  # Channel is the 4th dimension (zero-indexed)\n",
    "    name='Plate Data'\n",
    ")\n",
    "\n",
    "# Create widgets to navigate through wells, sites, and ZSteps\n",
    "@magicgui(\n",
    "    well={'widget_type': 'Slider', 'min': 0, 'max': data_shape[0] - 1, 'label': 'Well'},\n",
    "    site={'widget_type': 'Slider', 'min': 0, 'max': data_shape[1] - 1, 'label': 'Site'},\n",
    "    zstep={'widget_type': 'Slider', 'min': 0, 'max': data_shape[2] - 1, 'label': 'ZStep'}\n",
    ")\n",
    "def update_data(well: int = 0, site: int = 0, zstep: int = 0):\n",
    "    # Update the current slice based on selected well, site, and zstep\n",
    "    viewer.dims.set_point(0, well)\n",
    "    viewer.dims.set_point(1, site)\n",
    "    viewer.dims.set_point(2, zstep)\n",
    "\n",
    "# Add widget to Napari\n",
    "viewer.window.add_dock_widget(update_data)\n",
    "\n",
    "# Automatically adjust to display different channels (added as separate sliders)\n",
    "viewer.dims.axis_labels = ['Wells', 'Sites', 'ZSteps', 'Channels', 'X', 'Y']\n",
    "\n",
    "# Start Napari\n",
    "napari.run()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3839494b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from qtpy.QtWidgets import QLabel, QWidget, QVBoxLayout\n",
    "\n",
    "viewer = napari.view_image(\n",
    "        A_out,\n",
    "        channel_axis=2,\n",
    "        name=wavelengths,\n",
    "        colormap=colormap,\n",
    "        #contrast_limits=[[200, 4095], [500, 4095], [200, 4095]],\n",
    "        )\n",
    "\n",
    "# Create a custom widget to display the stack index\n",
    "class StackIndexWidget(QWidget):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.label = QLabel(\"Current stack index: 0\")\n",
    "        #self.label_file = QLabel(\"Filename w1\")\n",
    "        self.label_plate = QLabel(\"Plate: N/A\")\n",
    "        self.label_well = QLabel(\"Well: N/A\")\n",
    "        self.label_site = QLabel(\"Site: N/A\")\n",
    "        layout = QVBoxLayout()\n",
    "        layout.addWidget(self.label)\n",
    "        #layout.addWidget(self.label_file)\n",
    "        layout.addWidget(self.label_plate)\n",
    "        layout.addWidget(self.label_well)\n",
    "        layout.addWidget(self.label_site)\n",
    "        self.setLayout(layout)\n",
    "\n",
    "    def update_index(self, index):\n",
    "        self.label.setText(f\"Current stack index: {index}\")\n",
    "        #self.label_file.setText(f\"Filename w1: {df.loc[index, 'FileName_w1']}\")\n",
    "        self.label_plate.setText(f\"Plate: {df.loc[index, PLATE]}\")\n",
    "        self.label_well.setText(f\"Well: {df.loc[index, WELL]}\")\n",
    "        self.label_site.setText(f\"Site: {df.loc[index, SITE]}\")\n",
    "\n",
    "# Instantiate the custom widget\n",
    "stack_index_widget = StackIndexWidget()\n",
    "\n",
    "# Add the widget to Napari as a dock widget\n",
    "viewer.window.add_dock_widget(stack_index_widget, name=\"Stack Index\")\n",
    "\n",
    "# Callback function to update the widget with the current stack index\n",
    "def on_index_change(event):\n",
    "    current_index = viewer.dims.current_step[0]\n",
    "    stack_index_widget.update_index(current_index)\n",
    "\n",
    "# Connect the callback to the dims event\n",
    "viewer.dims.events.current_step.connect(on_index_change)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b188fbce",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Group by ZStep to handle stacking of channels for each Z-slice\n",
    "grouped_zstep = df3d.groupby(['Plate', 'Well', 'Site', 'ZStep'])\n",
    "\n",
    "# Prepare to collect Dask arrays for each ZStep\n",
    "dask_arrays = []\n",
    "\n",
    "for (plate, well, site, zstep), zstep_group in grouped_zstep:\n",
    "\n",
    "    channels = []\n",
    "    for channel_path in zstep_group[PATH]:\n",
    "        print(channel_path)\n",
    "        img = AICSImage(channel_path)\n",
    "        # Use img.get_image_dask_data() for lazy loading of data\n",
    "        channels.append(img.get_image_dask_data())\n",
    "\n",
    "    # Stack the images along a new dimension (channels)\n",
    "    dask_array = da.stack(channels, axis=0)  # Stack along the first axis for channels\n",
    "    dask_arrays.append((plate, well, site, zstep, dask_array))\n",
    "\n",
    "# Convert to DataFrame for ZStep level\n",
    "zstep_df = pd.DataFrame(dask_arrays, columns=['Plate', 'Well', 'Site', 'ZStep', 'DaskArray'])\n",
    "\n",
    "# Now group by Site to combine Dask arrays\n",
    "grouped_site = zstep_df.groupby(['Plate', 'Well', 'Site'])\n",
    "\n",
    "final_dask_arrays = []\n",
    "\n",
    "for (plate, well, site), group in grouped_site:\n",
    "    site_arrays = [entry[4] for entry in group.itertuples(index=False)]  # Extract Dask arrays for stacking\n",
    "    final_dask_array = da.concatenate(site_arrays, axis=0)  # Concatenate along the channel axis\n",
    "    final_dask_arrays.append((plate, well, site, final_dask_array))\n",
    "\n",
    "# Convert to DataFrame for Site level\n",
    "site_df = pd.DataFrame(final_dask_arrays, columns=['Plate', 'Well', 'Site', 'DaskArray'])\n",
    "\n",
    "# Finally, group by Well to combine arrays across Sites\n",
    "grouped_well = site_df.groupby(['Plate', 'Well'])\n",
    "\n",
    "well_dask_arrays = []\n",
    "\n",
    "for (plate, well), group in grouped_well:\n",
    "    well_arrays = [entry[3] for entry in group.itertuples(index=False)]  # Extract Dask arrays for stacking\n",
    "    well_dask_array = da.concatenate(well_arrays, axis=0)  # Concatenate across sites\n",
    "    well_dask_arrays.append((plate, well, well_dask_array))\n",
    "\n",
    "# Convert to DataFrame for Well level\n",
    "well_df = pd.DataFrame(well_dask_arrays, columns=['Plate', 'Well', 'DaskArray'])\n",
    "\n",
    "# Check the final DataFrame with Dask arrays for each Well\n",
    "print(well_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebe79544",
   "metadata": {},
   "outputs": [],
   "source": [
    "import dask.array as da\n",
    "import numpy as np\n",
    "\n",
    "def concat_da2d(selection, filename_cols, directory):\n",
    "    da_out = None\n",
    "    sites = []\n",
    "    for index, row in selection.iterrows():\n",
    "        channels = []\n",
    "        for f in filename_cols:\n",
    "            path = directory / row[f]\n",
    "            #print(str(path))\n",
    "            img = AICSImage(path)\n",
    "            #channels.append(img.data)\n",
    "            channels.append(img.get_image_dask_data())\n",
    "            #print(img.get_image_dask_data().shape)\n",
    "        site = da.concatenate(channels, axis=2)\n",
    "        sites.append(site)\n",
    "\n",
    "    da_out = da.concatenate(sites, axis=0)\n",
    "    return da_out\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abea7d37",
   "metadata": {},
   "outputs": [],
   "source": [
    "import dask.array as da\n",
    "\n",
    "dask_arrays = {}\n",
    "index_map = {}\n",
    "\n",
    "def channels2da(directory, filenames):\n",
    "    return da.stack([AICSImage(directory / f).get_image_dask_data() for f in filenames])\n",
    "    \n",
    "for (plate, well, site), group in grouped3d.iterrows():\n",
    "    # Assuming the file paths for the Z-slices are in group['file_paths']\n",
    "    dask_array = da.stack([channels2da(orig, fileset) for fileset in group[filename_cols]])\n",
    "    \n",
    "    # Store the Dask array and its corresponding index\n",
    "    dask_arrays[(well, site)] = dask_array\n",
    "    index_map[(well, site)] = len(dask_arrays) - 1  # Map (well, site) to Dask array index\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7dc5330d",
   "metadata": {},
   "outputs": [],
   "source": [
    "A_out = concat_da2d(df2d, filename_cols, orig)\n",
    "print(A_out.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "706d25d6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
